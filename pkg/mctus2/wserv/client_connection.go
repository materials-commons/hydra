package wserv

import (
	"bytes"
	"crypto/md5"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"os"
	"path/filepath"
	"sync"
	"time"

	"github.com/gorilla/websocket"
	"github.com/materials-commons/hydra/pkg/mcdb/mcmodel"
	"github.com/materials-commons/hydra/pkg/mcssh/mc"
)

// Message types
const (
	MsgUploadStart  = "UPLOAD_START"
	MsgUploadPause  = "UPLOAD_PAUSE"
	MsgUploadResume = "UPLOAD_RESUME"
	MsgUploadCancel = "UPLOAD_CANCEL"
	MsgGetStatus    = "GET_STATUS"
	MsgHeartbeat    = "HEARTBEAT"

	MsgClientConnected        = "CLIENT_CONNECTED"
	MsgClientDisconnected     = "CLIENT_DISCONNECTED"
	MsgUploadProgress         = "UPLOAD_PROGRESS"
	MsgUploadComplete         = "UPLOAD_COMPLETE"
	MsgUploadFailed           = "UPLOAD_FAILED"
	MsgClientStatus           = "CLIENT_STATUS"
	MsgListProjects           = "LIST_PROJECTS"
	MsgTransferInit           = "TRANSFER_INIT"
	MsgTransferAccept         = "TRANSFER_ACCEPT"
	MsgTransferReject         = "TRANSFER_REJECT"
	MsgChunkAck               = "CHUNK_ACK"
	MsgTransferComplete       = "TRANSFER_COMPLETE"
	MsgTransferFinalize       = "TRANSFER_FINALIZE"
	MsgTransferResume         = "TRANSFER_RESUME"
	MsgTransferResumeResponse = "TRANSFER_RESUME_RESPONSE"
	MsgTransferCancel         = "TRANSFER_CANCEL"
)

type Message struct {
	Command   string    `json:"command"`
	ID        string    `json:"id"`
	Timestamp time.Time `json:"timestamp"`
	ClientID  string    `json:"clientId"`
	Payload   any       `json:"payload"`
}

// ClientConnection represents a WebSocket client connection. A connection can be
// from a remote client such as the mc server on a users desktop or a Laravel UI client.
type ClientConnection struct {
	// ID is the unique identifier for this client connection. Each client has a unique ID,
	// which is generated by the remote client itself.
	ID   string
	Conn Connection

	// Send is a channel used to send messages to the client. The hub uses this channel to send
	// messages to the client. Internally, the client also uses the Send channel to send messages
	// that should be written on its socket connection. The readPump and writePump functions
	// handle the details of sending and receiving messages.
	Send chan Message

	// The Hub that this client belongs to. This is used to send messages to other clients. The
	// Hub takes care of routing the message to the proper client.
	Hub *Hub

	// The client type. This is used to determine which client type to use for this connection.
	// Currently there are two types: "ui" for the Laravel UI client and "server" for the Python
	// client.
	Type string

	// The client's hostname. Right now the UI uses this to identify the client's machine.
	Hostname string

	// The user that this client is connected as.
	User *mcmodel.User

	// The projects on the remote client. Only used for "server" connections and not "ui" connections.
	Projects []*mcmodel.Project

	// Track the remote client in the database. This gives access to the
	// transfer requests and associated files.
	RemoteClient *mcmodel.RemoteClient

	// Mutex to protect the Projects slice.
	mu sync.Mutex

	// File transfer state
	activeTransfers map[string]*FileTransfer

	// Mutex protecting activeTransfers
	transferMu sync.RWMutex
}

// readPump reads messages from the websocket connection and dispatches them. There are
// two cases it handles. For text messages it dispatches them to the Hub. Binary messages
// are file chunks and are handled separately. This keeps a fast path going for reading
// and writing file chunks, while still allowing the Hub to handle other messages. The
// readPump is the only method that reads from the websocket connection.
func (c *ClientConnection) readPump() {
	defer func() {
		c.Hub.WSManager.Unregister() <- c
		_ = c.Conn.Close()
	}()

	_ = c.Conn.SetReadDeadline(time.Now().Add(60 * time.Second))
	c.Conn.SetPongHandler(func(string) error {
		_ = c.Conn.SetReadDeadline(time.Now().Add(60 * time.Second))
		return nil
	})

	for {
		messageType, message, err := c.Conn.ReadMessage()
		if err != nil {
			if websocket.IsUnexpectedCloseError(err, websocket.CloseGoingAway, websocket.CloseAbnormalClosure) {
				log.Printf("WebSocket error: %v", err)
			}
			break
		}

		switch messageType {
		case websocket.TextMessage:
			var msg Message
			if err := json.Unmarshal(message, &msg); err != nil {
				log.Printf("Error unmarshalling message: %v", err)
				continue
			}
			msg.Timestamp = time.Now()
			log.Printf("Received message: command=%s from=%s", msg.Command, c.ID)
			c.handleMessage(msg)

		case websocket.BinaryMessage:
			// File chunks are binary messages. Currently only file chunks are sent in this format.
			c.handleFileChunk(message)
		}

	}
}

// writePump writes messages to the websocket connection. It periodically sends a ping message
// to keep the connection alive. It listens on the ClientConnection.Send channel for messages to
// send. The writePump is the only method that writes to the websocket connection.
func (c *ClientConnection) writePump() {
	ticker := time.NewTicker(20 * time.Second)
	defer func() {
		ticker.Stop()
		_ = c.Conn.Close()
	}()

	for {
		select {
		case message, ok := <-c.Send:
			_ = c.Conn.SetWriteDeadline(time.Now().Add(10 * time.Second))
			if !ok {
				_ = c.Conn.WriteMessage(websocket.CloseMessage, []byte{})
				return
			}

			if err := c.Conn.WriteJSON(message); err != nil {
				return
			}

		case <-ticker.C:
			_ = c.Conn.SetWriteDeadline(time.Now().Add(10 * time.Second))
			if err := c.Conn.WriteMessage(websocket.PingMessage, nil); err != nil {
				return
			}
		}
	}
}

// handleMessage dispatches messages to the appropriate handler based on the message's Command field.'
func (c *ClientConnection) handleMessage(msg Message) {
	fmt.Println("clienConnection::handleMessage", msg.Command)

	switch msg.Command {
	case MsgUploadStart, MsgUploadPause, MsgUploadResume, MsgUploadCancel, MsgGetStatus:
		// Forward control messages to target client
		c.Hub.WSManager.Broadcast() <- msg

	case MsgUploadProgress, MsgUploadComplete, MsgUploadFailed, MsgClientStatus:
		// Forward status messages to target client
		c.Hub.WSManager.Broadcast() <- msg

	case MsgListProjects:
		c.handleListProjects(msg)

	case MsgHeartbeat:
		// Respond to heartbeat
		response := Message{
			Command:   "HEARTBEAT_ACK",
			ID:        msg.ID,
			Timestamp: time.Now(),
			ClientID:  msg.ClientID,
		}
		c.Send <- response

	case MsgTransferInit:
		c.handleTransferInit(msg)

	case MsgTransferComplete:
		c.handleTransferComplete(msg)

	case MsgTransferResume:
		c.handleTransferResume(msg)

	case MsgTransferCancel:
		c.handleTransferCancel(msg)

	case MsgClientConnected:
		log.Printf("ClientConnection %s connected", msg.ClientID)

	case MsgClientDisconnected:
		log.Printf("ClientConnection %s disconnected", msg.ClientID)
	}
}

// ChunkHeader is the header part of a file chunk. A chunk consists of a text (JSON) header that is terminated
// by a newline character, followed by the chunk's binary data. The ChunkHeader is the JSON representation of
// that header.
type ChunkHeader struct {
	// TransferID is the ID of the transfer this chunk belongs to.
	TransferID string `json:"transfer_id"`

	// Sequence is the sequence number of this chunk within the transfer.
	Sequence int `json:"sequence"`

	// Size is the size of the chunk's binary data in bytes.
	Size int `json:"size"`

	// IsLast indicates whether this is the last chunk in the transfer.
	IsLast bool `json:"is_last"`
}

// broadcastProgress broadcasts the current progress of the given transfer to all UI clients for this user.
func (c *ClientConnection) broadcastProgress(transfer *FileTransfer) {
	progressMsg := Message{
		Command:   MsgUploadProgress,
		ID:        transfer.TransferID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id":   transfer.TransferID,
			"file_name":     transfer.FileName,
			"bytes_written": transfer.BytesWritten,
			"expected_size": transfer.ExpectedSize,
			"progress_pct":  float64(transfer.BytesWritten) / float64(transfer.ExpectedSize) * 100,
		},
	}

	_ = progressMsg
	// Broadcast to all UI clients for this user
	//c.Hub.broadcastToUserClients(c.User.ID, "ui", progressMsg)
}

// sendChunkError sends a chunk error message to the client.
func (c *ClientConnection) sendChunkError(transferID string, sequence int, reason string) {
	c.Send <- Message{
		Command:   "CHUNK_ERROR",
		ID:        transferID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id":    transferID,
			"chunk_sequence": sequence,
			"error":          reason,
		},
	}
}

// handleTransferInit handles the initialization of an upload transfer. It creates
// the transfer request and the ID associated with it, along with the mcmodel.File
// and mcmodel.TransferRequestFile association. It will send back to the client
// the transfer_id associated with this transfer.
func (c *ClientConnection) handleTransferInit(msg Message) {
	// TODO: This message should be a type and we have a function that deserializes and validates it.
	payload := msg.Payload.(map[string]interface{})
	fmt.Printf("handleTransferInit: %+v\n", payload)

	// The client sends details on the file to transfer, such as the name, size, and expected hash. It also
	// send the project and directory path to upload the file to. The client can optionally send the chunk
	// size. If it doesn't send a chunk size, then the server can set it or use the default (5mb).
	transferID, _ := payload["transfer_id"].(string)
	projectFilePath := payload["project_path"].(string)
	filePath, _ := payload["file_path"].(string)
	// JSON numbers are float64 that we cast to an int
	fileSize := int64(payload["file_size"].(float64))
	chunkSize := int(payload["chunk_size"].(float64))
	projectID := int(payload["project_id"].(float64))
	checksum := payload["checksum"].(string)

	// Validate
	if transferID == "" || filePath == "" || fileSize <= 0 {
		c.sendTransferReject(transferID, "invalid parameters")
		return
	}

	fileName := filepath.Base(projectFilePath)
	// Each upload will get a separate transfer request file. Transfers are tracked in the remote_client_transfers
	// table. Here we check to make sure that there isn't a transfer with this transfer_id.
	_, err := c.Hub.RemoteClientTransferStor.GetRemoteClientTransferByTransferID(transferID)
	if err == nil {
		c.sendTransferReject(transferID, "transfer already exists")
		return
	}

	fmt.Println("handleTransferInit: projectID", projectID, " UserID", c.User.ID)
	if !c.Hub.ProjectStor.UserCanAccessProject(c.User.ID, projectID) {
		c.sendTransferReject(transferID, "no access to project")
		return
	}

	if c.alreadyUploaded(projectID, filePath, checksum) {
		c.sendTransferReject(transferID, "file already uploaded")
		return
	}

	// Create the directory in the database if it doesn't exist
	dirPath := filepath.Dir(projectFilePath)
	dir, err := c.Hub.FileStor.GetOrCreateDirPath(projectID, c.User.ID, dirPath)
	if err != nil {
		c.sendTransferReject(transferID, "cannot create directory")
		return
	}

	// Create the file in the database, associate it with the directory, and associate it with a remote client transfer.
	f, err := c.Hub.FileStor.CreateFile(fileName, projectID, dir.ID, c.User.ID, mc.DetectMimeType(filePath))
	if err != nil {
		c.sendTransferReject(transferID, "cannot create file")
		return
	}

	remoteClientTransfer := &mcmodel.RemoteClientTransfer{
		State:            "uploading",
		TransferType:     "upload",
		TransferID:       transferID,
		ExpectedSize:     uint64(fileSize),
		ExpectedChecksum: checksum,
		RemotePath:       filePath, // Have the client send this
		OwnerID:          c.User.ID,
		ProjectID:        projectID,
		FileID:           f.ID,
		ChunkSize:        chunkSize,
		RemoteClientID:   c.RemoteClient.ID,
	}

	remoteClientTransfer, err = c.Hub.RemoteClientTransferStor.CreateRemoteClientTransfer(remoteClientTransfer)
	if err != nil {
		fmt.Printf("Error creating remote client transfer: %v\n", err)
		c.sendTransferReject(transferID, "cannot create transfer")
		return
	}

	// Create the file we are writing to
	file, err := f.CreateReturningHandleToUnderlyingFile(c.Hub.FileStor.Root())
	fmt.Printf("Created file at path: %+s\n", f.ToUnderlyingFilePath(c.Hub.FileStor.Root()))
	if err != nil {
		c.sendTransferReject(transferID, "cannot create file")
		return
	}

	// Optional: pre-allocate disk space
	if err := file.Truncate(fileSize); err != nil {
		file.Close()
		c.sendTransferReject(transferID, "cannot allocate space")
		return
	}

	// Create the in-memory transfer state
	transfer := &FileTransfer{
		TransferID:           transferID,
		ProjectID:            projectID,
		DirectoryID:          dir.ID,
		FileID:               f.ID,
		FileName:             fileName,
		FilePath:             filePath,
		File:                 file,
		ExpectedSize:         fileSize,
		BytesWritten:         0,
		ChunkSize:            chunkSize,
		remoteClientTransfer: remoteClientTransfer,
		NextChunkSeq:         0,
		LastActivity:         time.Now(),
		lastDBUpdate:         time.Now(),
	}

	c.transferMu.Lock()
	if c.activeTransfers == nil {
		c.activeTransfers = make(map[string]*FileTransfer)
	}
	c.activeTransfers[transferID] = transfer
	c.transferMu.Unlock()

	// Send acceptance
	c.Send <- Message{
		Command:   MsgTransferAccept,
		ID:        msg.ID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id":     transferID,
			"chunk_size":      int(chunkSize),
			"expected_chunks": int(fileSize) / int(chunkSize),
		},
	}

	log.Printf("Transfer initialized: %s (%s, %.2f MB)", transferID, fileName, fileSize/1024/1024)
}

func (c *ClientConnection) handleFileChunk(msg []byte) {
	// Parse header. The first part of the message is a newline terminated JSON string. After
	// that come the bytes for the file.
	newLineIdx := bytes.IndexByte(msg, '\n')
	if newLineIdx == -1 {
		log.Printf("Error parsing chunk header: %s", msg)
		return
	}
	headerBytes := msg[:newLineIdx]  // Bytes for the header, excluding newline character
	chunkBytes := msg[newLineIdx+1:] // Bytes for the chunk data, also skipping the newline character

	var header ChunkHeader
	if err := json.Unmarshal(headerBytes, &header); err != nil {
		log.Printf("Error parsing chunk header: %v", err)
		return
	}

	// Get the transfer state
	c.transferMu.RLock()
	transfer, ok := c.activeTransfers[header.TransferID]
	c.transferMu.RUnlock()
	if !ok {
		log.Printf("Received chunk for unknown transfer %s", header.TransferID)
		c.sendChunkError(header.TransferID, header.Sequence, "transfer not found")
		return
	}

	// Write the chunk to the underlying file
	if err := transfer.writeChunk(header.Sequence, chunkBytes); err != nil {
		log.Printf("Error writing chunk: %v", err)
		c.sendChunkError(header.TransferID, header.Sequence, "transfer not found")
		return
	}

	// transfer.updateProgressIfNeeded()

	// For now ACK every chunk. Later we can optimize this.
	c.Send <- Message{
		Command:   MsgChunkAck,
		ID:        header.TransferID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id":    header.TransferID,
			"chunk_sequence": header.Sequence,
			"bytes_received": transfer.BytesWritten,
			"next_sequence":  transfer.NextChunkSeq,
		},
	}

	// Broadcast progress to UI clients (every 10 chunks or so)
	//if header.Sequence % 10 == 0 {
	//	c.broadcastProgress(transfer)
	//}
}

// handleTransferComplete handles a transfer complete message from the client. It finishes the transfer, notifies the
// client on the status, as well as updates the users UI connections.
func (c *ClientConnection) handleTransferComplete(msg Message) {
	payload := msg.Payload.(map[string]interface{})
	transferID, _ := payload["transfer_id"].(string)

	// Get transfer
	c.transferMu.Lock()
	transfer, exists := c.activeTransfers[transferID]
	if !exists {
		c.transferMu.Unlock()
		c.sendTransferError(transferID, "transfer not found")
		return
	}
	delete(c.activeTransfers, transferID)
	c.transferMu.Unlock()

	// Finalize the file
	if err := c.finalizeTransfer(transfer); err != nil {
		log.Printf("Error finalizing transfer %s: %v", transferID, err)
		c.sendTransferError(transferID, err.Error())
		return
	}

	// Delete the transfer request from the database.
	if err := c.Hub.RemoteClientTransferStor.DeleteRemoteClientTransferByTransferID(transferID); err != nil {
		log.Printf("Error deleting transfer %s: %v", transferID, err)
	}

	// Send success response
	c.Send <- Message{
		Command:   MsgTransferFinalize,
		ID:        msg.ID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id":   transferID,
			"status":        "complete",
			"bytes_written": transfer.BytesWritten,
			"file_name":     transfer.FileName,
		},
	}

	// Notify UI clients
	completeMsg := Message{
		Command:   MsgUploadComplete,
		ID:        transferID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id": transferID,
			"file_name":   transfer.FileName,
			"file_size":   transfer.BytesWritten,
		},
	}
	c.Hub.WSManager.BroadcastToUser(c.User.ID, "ui", completeMsg)

	log.Printf("Transfer completed: %s (%s, %.2f MB)",
		transferID, transfer.FileName, float64(transfer.BytesWritten)/1024/1024)
}

// finalizeTransfer finalizes the given transfer by writing the final chunk to disk and updating the database record. It's
// called by handleTransferComplete after the transfer is complete.
func (c *ClientConnection) finalizeTransfer(transfer *FileTransfer) error {
	transfer.mu.Lock()
	defer transfer.mu.Unlock()

	// Flush and close the file
	if err := transfer.File.Sync(); err != nil {
		return fmt.Errorf("sync error: %v", err)
	}

	transfer.File.Close()

	// Verify file size
	fileInfo, err := os.Stat(transfer.FilePath)
	if err != nil {
		return fmt.Errorf("stat error: %v", err)
	}

	if fileInfo.Size() != transfer.ExpectedSize {
		return fmt.Errorf("size mismatch: expected %d, got %d",
			transfer.ExpectedSize, fileInfo.Size())
	}

	// TODO: Update to calculate the hash as we write chunks. Only do this if the hash state is out of date.

	f, err := c.Hub.FileStor.GetFileByID(transfer.FileID)
	if err != nil {
		return fmt.Errorf("file not found: %v", err)
	}

	fmt.Printf("Calculating hash for %s\n", transfer.FilePath)
	hash, err := calculateMD5(f.ToUnderlyingFilePath(c.Hub.FileStor.Root()))
	if err != nil {
		log.Printf("Warning: could not calculate hash: %v", err)
	}

	if hash != transfer.remoteClientTransfer.ExpectedChecksum {
		return fmt.Errorf("checksum mismatch: expected %s, got %s", transfer.remoteClientTransfer.ExpectedChecksum, hash)
	}

	// Update the file entry.
	switched, err := c.Hub.FileStor.DoneWritingToFile(f, transfer.remoteClientTransfer.ExpectedChecksum, transfer.ExpectedSize, c.Hub.ConversionStor)
	fmt.Printf("Switched file %d: %v\n", f.ID, switched)

	if err != nil {
		return fmt.Errorf("file update error: %v", err)
	}

	if switched {
		if err := os.Remove(f.ToUnderlyingFilePath(c.Hub.FileStor.Root())); err != nil {
			fmt.Printf("Failed to remove file %s: %s", f.ToUnderlyingFilePath(c.Hub.FileStor.Root()), err)
		}
	}

	return nil
}

func (c *ClientConnection) sendTransferError(transferID, reason string) {
	c.Send <- Message{
		Command:   MsgUploadFailed,
		ID:        transferID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id": transferID,
			"error":       reason,
		},
	}
}

// handleTransferResume will resume an upload request. The easy case is that the transfer is still
// in the c.activeTransfers map. If it's not, we need to check the database to see if the transfer
// exists. If it does, we need to check that the user owns the transfer and that the transfer hasn't
// already been completed. If all of those checks pass, we can open the file and resume writing.
func (c *ClientConnection) handleTransferResume(msg Message) {
	payload := msg.Payload.(map[string]interface{})
	transferID, _ := payload["transfer_id"].(string)

	// Check if the transfer is already active in memory
	c.transferMu.RLock()
	if _, exists := c.activeTransfers[transferID]; exists {
		c.transferMu.RUnlock()
		// Already active, just return the current state
		c.sendResumeResponse(transferID, c.activeTransfers[transferID])
		return
	}
	c.transferMu.RUnlock()

	// If we are here, then the transfer wasn't in the activeTransfers map. So lets retrieve it
	// from the database and reset up the state.
	remoteTransfer, err := c.Hub.RemoteClientTransferStor.GetRemoteClientTransferByTransferID(transferID)
	if err != nil {
		c.sendTransferReject(transferID, "transfer not found")
		return
	}

	// Verify this transfer belongs to this user
	if remoteTransfer.OwnerID != c.User.ID {
		c.sendTransferReject(transferID, "unauthorized")
		return
	}

	// Check if already complete
	if remoteTransfer.State == "complete" {
		c.sendTransferReject(transferID, "already completed")
		return
	}

	// Verify file exists on disk
	// TODO: We could just re-create the file and have the resume start from the beginning.
	fileInfo, err := os.Stat(remoteTransfer.File.ToUnderlyingFilePathForUUID(c.Hub.FileStor.Root()))
	if err != nil {
		c.sendTransferReject(transferID, "file not found on disk")
		return
	}

	// Open the file for writing
	file, err := os.OpenFile(remoteTransfer.File.ToUnderlyingFilePathForUUID(c.Hub.FileStor.Root()), os.O_WRONLY, 0644)
	if err != nil {
		c.sendTransferReject(transferID, "cannot open file")
		return
	}

	// Calculate where to resume from
	actualSize := fileInfo.Size()
	nextChunkSeq := int(actualSize / int64(remoteTransfer.ChunkSize))

	// Create the in-memory transfer state
	transfer := &FileTransfer{
		TransferID:           transferID,
		ProjectID:            remoteTransfer.ProjectID,
		DirectoryID:          remoteTransfer.File.DirectoryID,
		FileName:             filepath.Base(remoteTransfer.RemotePath),
		FilePath:             remoteTransfer.RemotePath,
		remoteClientTransfer: remoteTransfer,
		File:                 file,
		ExpectedSize:         int64(remoteTransfer.ExpectedSize),
		BytesWritten:         actualSize,
		ChunkSize:            remoteTransfer.ChunkSize,
		NextChunkSeq:         nextChunkSeq,
		LastActivity:         time.Now(),
		lastDBUpdate:         time.Now(),
	}

	c.transferMu.Lock()
	if c.activeTransfers == nil {
		c.activeTransfers = make(map[string]*FileTransfer)
	}
	c.activeTransfers[transferID] = transfer
	c.transferMu.Unlock()

	// Send resume response
	c.sendResumeResponse(transferID, transfer)

	log.Printf("Transfer resumed: %s (from byte %d / %d, %.1f%%)",
		transferID, actualSize, transfer.ExpectedSize,
		float64(actualSize)/float64(transfer.ExpectedSize)*100)
}

func (c *ClientConnection) sendResumeResponse(transferID string, transfer *FileTransfer) {
	c.Send <- Message{
		Command:   MsgTransferResumeResponse,
		ID:        transferID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id":       transferID,
			"can_resume":        true,
			"resume_from_byte":  transfer.BytesWritten,
			"resume_from_chunk": transfer.NextChunkSeq,
			"bytes_received":    transfer.BytesWritten,
			"expected_size":     transfer.ExpectedSize,
		},
	}
}

// handleTransferCancel will cancel a transfer request. Cancelling a transfer request
// will remove the following items from the database: RemoteClientTransfer, File associated
// with the RemoteClientTransfer. Note that if a directory was created for this transfer, it
// will be left in place. Lastly, this function will remove the underlying filesystem file
// this transfer was writing to.
func (c *ClientConnection) handleTransferCancel(msg Message) {
	payload := msg.Payload.(map[string]interface{})
	transferID, _ := payload["transfer_id"].(string) // TODO: Error check this

	// Remove from active transfers
	c.transferMu.Lock()
	transfer, exists := c.activeTransfers[transferID]
	if exists {
		delete(c.activeTransfers, transferID)
	}
	c.transferMu.Unlock()

	if !exists {
		// Nothing to do. Everything should have been cleaned up.
		return
	}

	// Close the OS file and delete it. We grab the lock on the transfer just in case another
	// thread is accessing the transfer.
	transfer.mu.Lock()
	transfer.File.Close()
	transfer.mu.Unlock()
	// Lets, remove the underlying filesystem file. We can safely ignore the error here.
	_ = os.Remove(transfer.remoteClientTransfer.File.ToUnderlyingFilePathForUUID(c.Hub.FileStor.Root()))

	// Delete the RemoteClientTransfer, and the File from the database.
	if err := c.Hub.RemoteClientTransferStor.DeleteRemoteClientTransferByTransferID(transferID); err != nil {
		log.Printf("Error deleting transfer %s: %v", transferID, err)
	}

	if err := c.Hub.FileStor.DeleteFileByID(transfer.remoteClientTransfer.File.ID); err != nil {
		log.Printf("Error deleting file %d: %v", transfer.remoteClientTransfer.File.ID, err)
	}

	// Send confirmation
	c.Send <- Message{
		Command:   "TRANSFER_CANCELLED",
		ID:        transferID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id": transferID,
		},
	}

	log.Printf("Transfer cancelled: %s", transferID)
}

func (c *ClientConnection) sendTransferReject(transferID, reason string) {
	fmt.Println("sendTransferReject:", transferID, reason)
	c.Send <- Message{
		Command:   MsgTransferReject,
		ID:        transferID,
		Timestamp: time.Now(),
		ClientID:  c.ID,
		Payload: map[string]interface{}{
			"transfer_id": transferID,
			"reason":      reason,
		},
	}
}

//func (c *ClientConnection) sendTransferAccept(transferID string) {
//	c.Send <- Message{
//		Command:   MsgTransferAccept,
//		ID:        msg.ID,
//		Timestamp: time.Now(),
//		ClientID:  c.ID,
//		Payload: map[string]interface{}{
//			"transfer_id":     transferID,
//			"chunk_size":      int(chunkSize),
//			"expected_chunks": int(fileSize) / int(chunkSize),
//		},
//	}
//}

type ProjectItem struct {
	Directory string `json:"directory"`
	ProjectID int    `json:"project_id"`
}

func (c *ClientConnection) handleListProjects(msg Message) {
	//fmt.Printf("handleListProjects: %+v\n", msg.Payload)
	projectsList := msg.Payload.([]interface{})
	for _, projectItem := range projectsList {
		projectItem := toProjectItem(projectItem.(map[string]interface{}))
		_ = projectItem
		//fmt.Printf("projectItem: %+v\n", projectItem)
	}
}

func toProjectItem(project map[string]interface{}) ProjectItem {
	return ProjectItem{
		Directory: project["directory"].(string),
		ProjectID: int(project["project_id"].(float64)),
	}
}

// handleHeartbeat handles HEARTBEAT messages from the client.
func (c *ClientConnection) handleHeartbeat(msg Message) error {
	response := Message{
		Command:   "HEARTBEAT_ACK",
		ID:        msg.ID,
		Timestamp: time.Now(),
		ClientID:  msg.ClientID,
	}
	c.Send <- response

	return nil
}

func (c *ClientConnection) alreadyUploaded(projectID int, filePath, checksum string) bool {
	// First check if there is a file matching checksum
	dirPath := filepath.Dir(filePath)
	fileName := filepath.Base(filePath)

	fmt.Println("alreadyUploaded:", projectID, dirPath, fileName, checksum)

	f, err := c.Hub.FileStor.FindMatchingFileByChecksum(checksum)
	if err != nil {
		// if we get an error then log it, and return false
		log.Printf("error finding file by checksum: %v", err)
		return false
	}

	if f == nil {
		// No file found with matching checksum
		fmt.Println("   1 false")
		return false
	}

	// If we are here, then a file matching the checksum was found.

	// 1. Check that the file actually exists on disk.
	if !f.RealFileExists(c.Hub.FileStor.Root()) {
		// File entry in database, but file doesn't exist on disk. So upload it.
		fmt.Println("   2 false")
		return false
	}

	// If the file exists on disk, then let's see if there is a matching file in the project at the same path
	existingFile, err := c.Hub.FileStor.GetFileByPath(projectID, filePath)
	if err == nil && existingFile != nil {
		// Check if the checksum matches. If it does, then there is nothing to do.
		if existingFile.Checksum == checksum {
			// Yes, there is a file matching the checksum with the same name.
			fmt.Println("   3 true")
			return true
		}
	}

	// If we are here then we found a file matching the checksum, that file is on disk, but we haven't
	// found a matching file in the project at the same path. We don't need to upload the file, we just
	// need to create a file entry in the database, point it at the existing file with the matching
	// checksums, and return true (file already uploaded).

	dir, err := c.Hub.FileStor.GetOrCreateDirPath(projectID, c.User.ID, dirPath)
	if err != nil {
		// error creating the directory... let's upload the file (what is the correct thing to do here?)
		log.Printf("error creating directory: %v", err)
		fmt.Println("   4 false")
		return false
	}

	createdFile, err := c.Hub.FileStor.CreateFile(fileName, projectID, dir.ID, c.User.ID, f.MimeType)
	if err != nil {
		log.Printf("error creating file entry: %v", err)
		fmt.Println("   5 false")
		return false
	}

	updates := mcmodel.File{
		Size:         f.Size,
		UsesUUID:     f.UUIDForUses(),
		UploadSource: "MCFT",
	}
	createdFile, err = c.Hub.FileStor.UpdateFile(createdFile, &updates)

	if err != nil {
		log.Printf("error updating file entry: %v", err)
		fmt.Println("   6 false")
		return false
	}

	if _, err := c.Hub.FileStor.SetFileAsCurrent(createdFile); err != nil {
		log.Printf("failed setting file %d as current: %s", f.ID, err)
		return false
	}

	if _, err := c.Hub.ConversionStor.AddFileToConvert(createdFile); err != nil {
		log.Printf("failed adding file %d to be converted: %s", f.ID, err)
	}

	fmt.Println("   7 true")
	return true
}

// Calculate MD5 hash of a file
func calculateMD5(path string) (string, error) {
	file, err := os.Open(path)
	if err != nil {
		return "", err
	}
	defer file.Close()

	hash := md5.New()
	if _, err := io.Copy(hash, file); err != nil {
		return "", err
	}

	return fmt.Sprintf("%x", hash.Sum(nil)), nil
}
